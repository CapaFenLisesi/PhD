\chapter{Optimization Techniques} \label{app:optimization}
In this appendix, we overview some technical aspects used in this thesis. More precisely, we describe two artificial intelligence techniques namely the Genetic Algorithms and the Particle Swarm Optimization widely used in optimization problems.

\section{Genetic Algorithms (GAs)}
Genetic Algorithms are stochastic methods inspired by the mechanism of natural evolution and genetic inheritance~\cite{Yeh:LRIR07}. GAs are are one of the most popular evolutionary algorithms widely used for solving optimization problems in many areas such as machine learning and image processing.  The idea behind is that the best solution can be found by combining the ``good'' parts of other solutions.

In GAs, a population is a set of \emph{chromosomes} (candidate solutions) and each chromosome denotes a set of \emph{genes}. The content of each gene is called \emph{allele}. A key component in GAs is the setting of a fitness criterion which accurately evaluates the quality of candidate solutions. First, a population of chromosomes are randomly generated and evaluated using the fitness function. The chromosomes having higher fitness values than others are stochastically selected, recombined and mutated to produce a new population for the next generation. To achieve this, GA has a set of key operators, namely \emph{selection}, \emph{crossover} and \emph{mutation}. The selection operator is used to select chromosomes called \emph{parents} to create the descendants of the next generation. The selection usually favored fitter patents, and there are approaches proposed in the literature. One example is the \emph{Stochastic Universal Sampling (SUS)} developed by Baker~\cite{Baker:1987}, which is used in this thesis. Consider a line where each chromosome occupies a segment proportional to the chromosome's fitness. \emph{SUS} uses $N$ equally spaced pointers placed over the line, where $N$ is the number of selections required.

Once parents for new population are chosen, genetic operators are applied such as crossover and mutation. Crossover refers to the recombination of parents to form a child. In particular, we used the scattered crossover which creates a random binary mask, then selecting the genes where the mask is 1 from one parent, and the rest from other parent. In order to force the algorithm exploring new areas in the search space, mutation is performed which alters at least one gene in a chromosome according to a predefined probability. Mutation rarely occurs in nature, which can justify the typical value 0.01 generally used as a mutation probability. Finally, the algorithm stops iterating when the optimal solution is produced or a maximal number of iterations is reached.

\section{Particle Swarm Optimization (PSO)}
It is a population-based stochastic optimization technique inspired by the social behavior of bird flocking or fish schooling~\cite{Kennedy:ICNN95}. PSO is similar to evolutionary algorithms and it was introduced in 1995 by Kennedy and Eberhat. Compared with GA, PSO is easy to implement with few parameters to adjust, and each individual  benefits from its history whereas no such mechanism exists in GA. PSO has been successfully applied to solving a wide range of optimization problems in different fields such as robotics, image, neural network, and information retrieval.

PSO simulates a group of birds searching for food in a bounded area, where the best position is the one containing the highest density of food. At the beginning, all the birds start searching for food randomly. Each bird knows two positions: its own position (i.e. history) found with the most of food and the best position from the whole swarm. The birds will be guided by these two positions in the search process until optimal convergence.

The PSO algorithm initializes a population of random solutions called \emph{swarms} or \emph{particles}, and searches for the optimal solution of a fitness function by updating generations. In each generation, each particle accelerates in the direction of its own personal best solution found so far, as well as in the direction of the global best position discovered so far by any of the particles in the swarm. This means that if a particle discovers a promising new solution, all the other particles will move closer to it, exploring the region more thoroughly in the search process. Each particle $i$ in the swarm has the following attributes: a current position $x_{i}$, a current velocity $v_{i}$, and a personal best position $p_{i}$ in the search space, and the global best position $p_{gbest}$ among all the $p_{i}$. In each iteration, the velocity and the position of each particle is updated as following:

\begin{gather*}
  v_{i}(t+1)= w . v_{i}(t) + c_{1} r_{1} (p_{i} - x_{i}(t)) + c_{2} r_{2} (p_{gbest} - x_{i}(t)) \\
  x_{i}(t+1)=x_{i}(t)+v_{i}(t+1) \\
\end{gather*}
where $c_{1}$ is the acceleration coefficient for each particle to move to its personal best position, $c_{2}$ is the acceleration coefficient to move to the global best position, $r_{1}$ and $r_{2}$ are random numbers uniformly distributed within [0,1], and $w$ is the inertia weight which controls the contribution of a particle's previous velocity to its current velocity. The velocity and acceleration are responsible for changing the position of the particle to explore the space of all possible solutions, instead of using existing solutions to reproduce. The personal and the global best positions are the optima of a predefined fitness function, respectively in each iteration and for all past iterations. In this thesis, to adjust some PSO parameters, we followed the setting recommended by Eberhart and Shi~\cite{Eberhart:CEC01}.